{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c829771f-e8cb-47f6-907a-6dfddb822e7c",
   "metadata": {},
   "source": [
    "# 1) Importing Dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e8d80938-bd53-4268-82a0-3015d42c4f85",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import uuid\n",
    "import os\n",
    "import time"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8bcc430-3664-49d5-838b-26be06a4d36e",
   "metadata": {},
   "source": [
    "uuid is a module which will be used to generate unique ids.<br>\n",
    "Ref : https://docs.python.org/3/library/uuid.html"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3bf4c6a3-ca4c-4105-87c7-1b07bbf2aeee",
   "metadata": {},
   "source": [
    "# 2) Defining Labels For Various Hand Signs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee595046-cdda-4d6d-981f-6d5dfce1d3f1",
   "metadata": {},
   "source": [
    "The model will detect different gestures as objects. The gestures \"ok\",\"notok\",\"thankyou\",\"livelong\",\"name\",\"what\",\"you\",\"iloveyou\",\"nice\",\"love\" are the objects."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "66ef97d8-d811-42ee-a757-36cb5881feeb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Labels is a list which contains the name of all the handsigns that will be detected by our model\n",
    "labels = [\"ok\",\"notok\",\"thankyou\",\"livelong\",\"name\",\"what\",\"you\",\"iloveyou\",\"nice\",\"love\"]\n",
    "number_img=30"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3bf68087-5251-4347-abe6-8bf64f273c1e",
   "metadata": {},
   "source": [
    "# 3) Setup Paths For Folders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "525bd760-e3f9-4c2a-b0ee-604bce32a757",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Tensorflow\\\\workspace\\\\images\\\\collectedimages'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# This cell will setup the path for the image data\n",
    "IMAGES_PATH = os.path.join('Tensorflow','workspace','images','collectedimages')\n",
    "IMAGES_PATH"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "93843faa-cd57-40a3-b941-b27ee537027f",
   "metadata": {},
   "outputs": [],
   "source": [
    "if not os.path.exists(IMAGES_PATH):\n",
    "    if os.name=='posix':\n",
    "        !mkdir -p{IMAGES_PATH}\n",
    "    if os.name=='nt':\n",
    "        !mkdir {IMAGES_PATH}\n",
    "for label in labels:\n",
    "    path = os.path.join(IMAGES_PATH,label)\n",
    "    if not os.path.exists(path):\n",
    "        !mkdir {path}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7c960c3-ff19-4b36-ba35-45680e785c7a",
   "metadata": {},
   "source": [
    "In the above cell the if condition is used to check what OS is the code running on for eg. if the code is being run on google colab then it will be using a linux machine so os.name will be 'posix' whereas in case of windows it will be 'nt'.\n",
    "After determining the whether the path exists or not and which OS it is; it creates a directory for the path specified in IMAGES_PATH and then using a loop it generates the path and directory for each label."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74f0306f-f8b0-4ce3-8ac6-a7c9614bd6c3",
   "metadata": {},
   "source": [
    "# 4) Capture Images With Handsigns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1ed2879d-f6e3-45d3-8ab7-69dd7f55c4cd",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting images for ok\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_16956/669083993.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      2\u001b[0m     \u001b[0mcap\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcv2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mVideoCapture\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Collecting images for {}\"\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlabel\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 4\u001b[1;33m     \u001b[0mtime\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msleep\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m10\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      5\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0mimgnum\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnumber_img\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m         \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Collecting images for {}\"\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mimgnum\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "for label in labels:\n",
    "    cap=cv2.VideoCapture(1)\n",
    "    print(\"Collecting images for {}\".format(label))\n",
    "    time.sleep(10)\n",
    "    for imgnum in range(number_img):\n",
    "        print(\"Collecting images for {}\".format(imgnum))\n",
    "        ret,frame=cap.read()\n",
    "        imgname=os.path.join(IMAGES_PATH,label,label+'.'+'{}.jpg'.format(str(uuid.uuid1())))\n",
    "        cv2.imwrite(imgname,frame)\n",
    "        cv2.imshow('frame',frame)\n",
    "        time.sleep(2)\n",
    "        if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "            break\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3084511-ea0c-4b2d-9b4b-48f6081fa04d",
   "metadata": {},
   "source": [
    "# 5) Labelling Images"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90b1405d-e6aa-4f2a-9247-6fff3c74b3c2",
   "metadata": {},
   "source": [
    "Cloned the repository https://github.com/tzutalin/labelImg to label the collected images for various handsigns. The name of repository is Labelimg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2143fc83-c6d1-4afb-a14f-42bb260ec017",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Tensorflow\\\\labelimg'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Creating a new directory path for labelled images\n",
    "Label_Img_Path = os.path.join('Tensorflow','labelimg')\n",
    "Label_Img_Path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "31d84a92-6e5e-4f59-b7cb-00b6d679655b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Cloning into 'Tensorflow\\labelimg'...\n"
     ]
    }
   ],
   "source": [
    "# Creating the directory for labelled images and then cloning the repository\n",
    "if not os.path.exists(Label_Img_Path):\n",
    "    !mkdir {Label_Img_Path}\n",
    "    !git clone https://github.com/tzutalin/labelImg {Label_Img_Path}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1e5a624e-37f4-408f-988d-380e46b7ff85",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Installing the labelimg package as mentioned in the readme.md of the repository\n",
    "if os.name == 'posix':\n",
    "    !cd {Label_Img_Path} && make qt5py3\n",
    "if os.name == 'nt':\n",
    "    !!cd {Label_Img_Path} && pyrcc5 -o libs/resources.py resources.qrc"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc84a545-779e-43c5-8441-3e1a1bcda850",
   "metadata": {},
   "source": [
    "Now we run the installed labelimg package and label the captured image, however some points being taken into account are:<br>\n",
    "1) The name of labels is in camel case.<br>\n",
    "2) The labelling is done as tight as possible."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8aadd342-b77e-41d8-a096-43785ee5141a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "!cd {Label_Img_Path} && python labelImg.py"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "938589bd-f844-416b-9067-bb45817648a8",
   "metadata": {},
   "source": [
    "# 6) Separating the images into test and train folders"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "863f6684-704b-4b33-8980-62ae9231b49e",
   "metadata": {},
   "source": [
    "24 images per class with annotations will be used as training data which is 240 images and for testing there will be 60 images i.e. 6 images per class.<br>\n",
    "In the Model Training and Predictions.ipynb, we convert the images present in the train and test into Tensorflow records, and then using these records the model will be trained.<br>\n",
    "Note: Tensorflow Records is a protobuf format that makes it possible for the training program to buffer, prefetch, and parallelize the reading of records. So, a good first step for machine learning is to convert your industry-specific binary format files into TensorFlow records."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "HSDtf",
   "language": "python",
   "name": "hsdtf"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
